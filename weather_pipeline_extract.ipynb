{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\nsession = SparkSession.builder.appName('sparksession').getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"8b123c44-7a07-4809-9359-7b6b5fb87d53","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import *\nfrom pyspark.sql.functions import *\n\nimport uuid"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"48c2f7ef-6e43-4331-9c97-89bd02ef617c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%run /Users/tha075bei026@tcioe.edu.np/actionLogger"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"61c5747c-4128-416b-9200-08dfd44334bd","inputWidgets":{},"title":"Calling actionLogger notebook and executing it"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["session.sql('use weather')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b34920c1-ea7a-44de-b72f-fa251074945d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[8]: DataFrame[]"]}],"execution_count":0},{"cell_type":"code","source":["session.sql('select current_schema()').show()\nsession.sql('show tables').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"9f6b0d5a-0f61-46fe-84f9-e34e6f2522f2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+------------------+\n|current_database()|\n+------------------+\n|           weather|\n+------------------+\n\n+--------+---------+-----------+\n|database|tableName|isTemporary|\n+--------+---------+-----------+\n| weather|log_table|      false|\n+--------+---------+-----------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["\nlog_schema = StructType([\n    StructField(\"id\",StringType()),\n    StructField(\"load_type\", StringType()),\n    StructField(\"table_name\", StringType()),\n    StructField(\"process_start_time\", TimestampType()),\n    StructField(\"process_end_time\", TimestampType()),\n    StructField(\"status\", StringType()),\n    StructField(\"comments\", StringType()),\n    StructField(\"start_date_time\", TimestampType()),\n    StructField(\"end_date_time\", TimestampType()),\n    StructField(\"created_on\", TimestampType()),\n    StructField(\"created_by\", StringType())\n\n])\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1d01a1a1-a0f0-45a6-9234-22840ba29c97","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def flatten_json(dict_col):\n     for i in dict_col:\n        value = dict_col[i]\n        \n        if isinstance(value, dict):\n            yield from flatten_json(value)\n        elif isinstance(value, list):\n            for item in value:\n                yield from flatten_json(item)\n        else:\n            yield value\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"94757902-1b3e-4df3-a2a7-959f5bf695b6","inputWidgets":{},"title":"function to flatten nested json"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["\nsource_weather_schema = StructType([\n   \n    StructField('lon', DoubleType()),\n    StructField('lat', DoubleType()),\n    \n   \n    StructField('description_id', IntegerType()),\n    StructField('main', StringType()),\n    StructField('description', StringType()),\n    StructField('icon', StringType()),\n    \n    StructField('base', StringType()),\n    \n\n    StructField('temp', StringType()),\n    StructField('feels_like', DoubleType()),\n    StructField('temp_min', StringType()),\n    StructField('temp_max', StringType()),\n    StructField('pressure', IntegerType()),\n    StructField('humidity', IntegerType()),\n    StructField('sea_level', IntegerType()),\n    StructField('grnd_level', IntegerType()),\n    \n    StructField('visibility', StringType()),\n\n    StructField('wind_speed', DoubleType()),\n    StructField('wind_deg', IntegerType()),\n    StructField('wind_gust', DoubleType()),\n    \n    StructField('all',IntegerType()),\n    \n    StructField('dt', IntegerType()),\n  \n    StructField('country', StringType()),\n    StructField('sunrise', IntegerType()),\n    StructField('sunset', IntegerType()),\n    \n    StructField('timezone', IntegerType()),\n    StructField('id', IntegerType()),\n    StructField('name', StringType()),\n    StructField('cod', IntegerType()),\n    \n   \n    \n])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b064c65f-7110-45d8-9ff9-0f281bb7ecc9","inputWidgets":{},"title":"source data schema definition"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import json\nimport requests\nfrom requests.auth import HTTPDigestAuth\nfrom pyspark.sql import Row\n\ndef data_from_api(city_id):\n    url = 'https://api.openweathermap.org/data/2.5/weather?id=' + str(city_id) + '&appid=ae0bb98bc50300db4831762db7096897'\n    response = requests.get(url)\n    if(response.ok):\n        jsdata = response.content\n        jsdata = json.loads(jsdata)\n        values = [value for value in flatten_json(jsdata)]\n        df = session.createDataFrame(data = ([values]) ,schema = source_weather_schema)\n        return df\n    else:\n        print('Error!')\n        return response.status_code"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"c008f9b2-ab3d-4a6a-bc34-e9991b130e96","inputWidgets":{},"title":"function to extract data from api"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["city_data = session.read.format('delta').load('dbfs:/user/hive/warehouse/cities').limit(5)\ncity_id = city_data.select(city_data['id']).rdd.flatMap(lambda x: x).collect()\n# city_id"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d614601f-dad2-4dd3-92d0-0838679d70c2","inputWidgets":{},"title":"extracting cities id from previous task table"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["\n\ndef load_raw_data():\n    \n    log_dict = {'id': str(uuid.uuid4().hex),\n            'load_type': 'raw',\n            'table_name': 'raw_weather_table',\n    \n            'process_start_time': session.sql(\"SELECT current_timestamp()\").collect()[0][0],\n            'process_end_time': session.sql(\"SELECT current_timestamp()\").collect()[0][0],\n\n            'start_date_time':  session.sql(\"SELECT current_timestamp()\").collect()[0][0],\n            'end_date_time':  session.sql(\"SELECT current_timestamp()\").collect()[0][0]}\n    \n    log = action_logger(log_dict)\n    \n    created_on = session.sql(\"SELECT current_timestamp()\").collect()[0][0]\n    created_by = session.sql('select current_user()').collect()[0][0]\n    \n    process_start_time = session.sql(\"SELECT current_timestamp()\").collect()[0][0]\n    \n    city_data = [data_from_api(int(float(id))) for id in city_id]\n    \n    if not isinstance(city_data[0],DataFrame):\n        process_end_time = session.sql(\"SELECT current_timestamp()\").collect()[0][0]\n        comments = 'error with status code' + str(city_data[0])\n        error_dict = {\n               'process_start_time' : process_start_time,\n               'process_end_time' : process_end_time,\n               'status' : 'error',\n               'error_data' : comments,\n               'start_date_time' : session.sql(\"SELECT current_timestamp()\").collect()[0][0],\n               'end_date_time' : session.sql(\"SELECT current_timestamp()\").collect()[0][0]\n        }\n        log.action(error_dict)\n    else:\n        try:\n            raw_city_all = city_data[0]\n            for each in city_data[1:]:\n                raw_city_all = raw_city_all.union(each)\n            \n            raw_city_all = raw_city_all.withColumn(\"load_run_id\",lit(str(uuid.uuid4().hex)))\\\n                                    .withColumn(\"created_on\",lit(created_on))\\\n                                    .withColumn(\"created_by\", lit(created_by))\n            \n            raw_city_all = raw_city_all.distinct()\n            \n            process_end_time = session.sql(\"SELECT current_timestamp()\").collect()[0][0]\n            \n            log_dict = {\n               'process_start_time' : process_start_time,\n               'process_end_time' : process_end_time,\n               'status' : 'extracting',\n               'start_date_time' : raw_city_all.select(min('created_on')).first()[0],\n               'end_date_time' : raw_city_all.select(max('created_on')).first()[0]}\n            \n            log.action(log_dict)\n            \n    \n#             raw_city_all.write.format('delta').mode('append').save('dbfs:/databases/weather/weather_table_raw')\n            raw_city_all.write.option(\"overwriteSchema\", \"true\")\\\n                .format('delta')\\\n                .mode('append')\\\n                .save('dbfs:/databases/weather/raw_weather_table')\n        \n            process_end_time = session.sql(\"SELECT current_timestamp()\").collect()[0][0]\n            \n            log_dict = {\n               'process_start_time' : process_start_time,\n               'process_end_time' : process_end_time,\n               'status' : 'completed',\n               'start_date_time' : raw_city_all.select(min('created_on')).first()[0],\n               'end_date_time' : raw_city_all.select(max('created_on')).first()[0]}\n            log.action(log_dict)\n                \n        except Exception as e:\n                error_dict = {\n               'process_start_time' : process_start_time,\n               'process_end_time' : session.sql(\"SELECT current_timestamp()\").collect()[0][0],\n               'status' : 'error',\n               'error_data' : e,\n               'start_date_time' : session.sql(\"SELECT current_timestamp()\").collect()[0][0],\n               'end_date_time' : session.sql(\"SELECT current_timestamp()\").collect()[0][0] }\n                log.action(error_dict)\n    \n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6a195aa0-7b0f-45d5-af5f-fb277c0273db","inputWidgets":{},"title":"function to load data in raw data table"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# load_raw_data()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"24080042-0b47-444f-a9a3-61a9a2f03f9a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"weather_pipeline_extract","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
